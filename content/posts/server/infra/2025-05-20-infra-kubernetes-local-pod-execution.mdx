---
title: kubernetes 로컬 kind에서 ECR 이미지로 pod 실행
date: 2025-05-20
slug: "/infra/2025-05-20-infra-kubernetes-local-pod-execution"
tags:
  - INFRA
  - 2025
---

# 배경
staging 은 쿠버네티스 환경이다
젠킨스 파이프라인을 활용해서 docker 이미지를 빌드 push 하고 staging 에
앱을 배포하려고 한다

ECR 까지 이미지를 빌드 했고
로컬에서 AWS ECR 이미지를 받아와 쿠버네틱스 파드를 실행하려고 한다

 # 로컬에서 설치할것
1. kubectl -> brew install kubectl ,kubectl version 확인
2. kind  -> brew install kind , kind version
3. docker
4. helm ->  brew install helm

# ECR 이미지 다운받고 pod 실행 - 앱을 로컬에서 실행

1. AWS ECR에 로그인하여 Docker 이미지 Pull/Push를 허용하는 인증 명령어
```
aws ecr get-login-password --region ap-northeast-2 | \
docker login --username AWS --password-stdin 123456789012.dkr.ecr.ap-northeast-2.amazonaws.com
```

2. Docker에서 ECR 이미지 pull
```
docker pull 123456789012.dkr.ecr.ap-northeast-2.amazonaws.com/test-sharing-service:latest
```
`docker images` 로 다운받은 이미지 확인
* tip Docker Scout란?
Docker Scout는 pulled된 이미지에 대해 다음을 자동으로 수행
취약점 스캔 (CVEs) 보안 업데이트 제안 이미지 분석 결과를 Docker Desktop에서 확인 가능

* tip AWS ECR 에서 실제 이미지 이름 조회해서 tag 등 확인 가능
```
aws ecr describe-images \
  --repository-name test-sharing-service \
  --region ap-northeast-2
```

```
"imageTags": [
"latest"
]
```

3. 로컬에 클러스터 생성
kind 활용: Kubernetes 실습/테스트 환경에서 로컬에서 클러스터를 만들 수 있게 해주는 도구
쿠버네티스를 로컬에서 빠르게 실습하고 테스트하고 싶을때 활용

| 목적                 | 명령어                           |
| ------------------ | ----------------------------- |
| 클러스터 목록 보기         | `kind get clusters`           |
| PC에 K8s 클러스터 구성    | `kind create cluster --name test` |
| 현재 kubectl 컨텍스트 보기 | `kubectl config get-contexts` |
| 클러스터 전체 리소스 보기     | `kubectl get all -A`          |
| 노드 보기              | `kubectl get nodes`           |
| 클러스터 정보 보기         | `kubectl cluster-info`        |

kind는 내부적으로 Docker 컨테이너를 사용해서
`docker ps` 실행시 kind-control-plane 이라는 이름의 컨테이너가 실행 중인 걸 확인할 수 있다

|CONTAINER ID |  IMAGE     |             PORTS           |            NAMES|
|---|---|---|---|
|11111|   kindest/node:v1.33.1   | 127.0.0.1:64964->6443/tcp  | kind-control-plane|

4. kind 클러스터에 이미지 import
```
kind load docker-image 123456789012.dkr.ecr.ap-northeast-2.amazonaws.com/test-sharing-service:latest --name test
```

5. 직접 Pod 만들어보자
`nano my-pod.yaml`
```
apiVersion: v1
kind: Pod
metadata:
  name: test-service-pod
spec:
  containers:
    - name: test-service
      image: 123456789012.dkr.ecr.ap-northeast-2.amazonaws.com/test-sharing-service:latest
      ports:
        - containerPort: 9010
```

`kubectl apply -f my-pod.yaml` 적용시 pod/test-service-pod 생성
`kubectl get pods ` 로 실행 확인

# 로컬에서 실행한 앱과 mysql 연동
로컬에 pods 추가햤지만 실행되고 꺼지고 있다
CrashLoopBackOff은 정상적인 앱 종료가 아닌 경우로
`kubectl logs test-service-pod` 로 로그를 봤더니
DB 연결 실패다

### 문제
로컬 PC에 있는 MySQL DB에 접근하는 것이 아니다
쿠버네티스 클러스터 안에 새로운 MySQL을 생성해서 그 DB에 접근 해야한다

### 해결
Helm을 이용해 클러스터 안에 MySQL을 띄우고
NestJS 앱에서 이 MySQL에 연결
1.  Bitnami MySQL 차트 추가

Bitnami라는 Helm Chart 저장소를 내 로컬 Helm에 등록하고 최신 목록으로 갱신
Helm을 처음 설치하면 기본 저장소가 아무것도 없기때문에
외부 저장소를 내 Helm에 등록하는 작업을함

```
helm repo add bitnami https://charts.bitnami.com/bitnami # bitnami 라는 Helm 저장소를 내 로컬 Helm에 등록
helm repo update      # 최신 Chart 목록 반영
```
방금 등록한 저장소(bitnami)에서 mysql Chart를 받아와서
내 클러스터에 MySQL을 설치

`nano mysql-values.yaml`
```
auth:
  rootPassword: "1234"
  username: "user"
  password: "1234"
  database: "test"
```
`helm install my-mysql bitnami/mysql -f mysql-values.yaml`
수정 후
`helm upgrade my-mysql bitnami/mysql -f mysql-values.yaml`

* 삭제하고 싶다면 + 데이터(pvc) 자동 삭제되지 않아서 수동 삭제
` helm uninstall my-mysql`
`kubectl delete pvc -l app.kubernetes.io/instance=my-mysql`

###  my-pod.yaml DB환경 변수 추가
`nano my-pod.yaml `
```
...
ports:
    - containerPort: 9010
env:
        - name: DB_HOST
          value: my-mysql.default.svc.cluster.local
        - name: DB_PORT
          value: "3306"
        - name: DB_USER
          value: "user"
        - name: DB_PASSWORD
          value: "1234"
        - name: DB_NAME
          value: test
```
변경된 내용 저장하고 같은 이름 파드 지우고 다시 적용시키기
`kubectl delete pod gift-service-pod`
`kubectl apply -f my-pod.yaml`

